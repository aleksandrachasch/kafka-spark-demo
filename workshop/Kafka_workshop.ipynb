{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349b4601-d5bd-41da-8e19-05d1d6040945",
   "metadata": {},
   "source": [
    "# Воркшоп по Kafka и Spark Structured Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb83ec6-c6fd-4717-813d-5a438a7920fc",
   "metadata": {},
   "source": [
    "Есть бэкенд система, которая обрабатывает покупки. Эта система в режиме реального времени отправляет данные в топик Kafka `yp.workshop.kafka.retail_data` в формате JSON. Например:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"InvoiceNo\":\"536365\",\n",
    "   \"StockCode\":\"85123A\",\n",
    "   \"Description\":\"WHITE HANGING HEART T-LIGHT HOLDER\",\n",
    "   \"Quantity\":\"6\",\n",
    "   \"InvoiceDate\":\"12/1/2010 8:26\",\n",
    "   \"UnitPrice\":\"2.55\",\n",
    "   \"CustomerID\":\"17850\",\n",
    "   \"Country\":\"United Kingdom\"\n",
    "}\n",
    "```\n",
    "\n",
    "Есть другая бэкенд система, которая обрабатывает данные пользователей. Эта система также в режиме реального времени отправляет данные в топик Kafka `yp.workshop.kafka.customer_data` в формате JSON. Например:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"CustomerID\":\"12346\",\n",
    "   \"Address\":\"Unit 1047 Box 4089\\nDPO AA 57348\",\n",
    "   \"Birthdate\":\"1994-02-20 00:46:27\",\n",
    "   \"Email\":\"cooperalexis@hotmail.com\",\n",
    "   \"Name\":\"Lindsay Cowan\",\n",
    "   \"Username\":\"valenciajennifer\"\n",
    "}\n",
    "```\n",
    "\n",
    "Данные и в том, и в другом случае отправляются при **изменении или создании**.\n",
    "\n",
    "Есть запрос создать страницу в личном кабинете каждого клиента, где бы отображалась вся история его покупок. Допустим, что эти данные будут поступать на фронтенд через API.\n",
    "\n",
    "Задача - написать пайплайн, который в потоковом режиме будет преобразовывать сообщения о покупках таким образом, чтобы API смог забрать данные по каждому клиенту с актуальным списком покупок. \n",
    "\n",
    "Базовый стек: \n",
    "- Spark Structured Streaming\n",
    "- MongoDB\n",
    "\n",
    "Можно добавить любую другую технологию или базу данных, если это необходимо. Цель - сделать так, чтобы данные о покупке поступали как можно скорее на API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd50b7-22e6-4054-be6b-d65b2406bd82",
   "metadata": {},
   "source": [
    "## Задание 0\n",
    "\n",
    "Все логи по умолчанию пишутся в консоль. Чтобы увидеть их в ноутбуке, необходимо выполнить следующие действия:\n",
    " - В консоли докера с `pyspark` выполнить команду `ipython profile create`;\n",
    " - В файле `.ipython/profile_default/ipython_kernel_config.py` раскомментировать строку `c.IPKernelApp.capture_fd_output = True`;\n",
    " - Перезапустить `kernel` в ноутбуке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e80c44-db7d-42af-b202-8c809ac68d9d",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "Спроектировать пайплан. Можно нарисовать схему с базами данных, топиками Kafka и процессами Spark. Также можно опустить часть того, каким образом данные отправляются через API на фронтенд - это сейчас не так важно. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d190d7f-2f8e-4d76-8a93-f83e55fb4511",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Подключиться к топику с помощью `Spark DataFrameStreamReader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99ea0e-9fd6-4b07-82ba-72e7f92617f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.streaming.listener import StreamingListener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ae990-ef47-4bc6-a052-cf7febf016cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создать сессию Spark\n",
    "spark = \"\"\" НАПИШИТЕ ВАШ КОД ЗДЕСЬ \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6dc6f-1b18-4826-af58-71bad9d73b61",
   "metadata": {},
   "source": [
    "Настройка `ReadStream`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341390d-2aef-4c95-918f-8449b9865d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_user = 'de-student'\n",
    "kafka_pass = 'ltcneltyn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f03ca-c453-49c9-8eb1-02aa12eae6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_retail = 'yp.workshop.kafka.retail_data'\n",
    "\n",
    "df_retail = spark.readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091') \\\n",
    "    .option('kafka.security.protocol', 'SASL_SSL') \\\n",
    "    .option('kafka.sasl.jaas.config', f'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"{<Ваш код>}\" password=\"{<Ваш код>}\";') \\\n",
    "    .option('kafka.partition.assignment.strategy', 'org.apache.kafka.clients.consumer.RoundRobinAssignor') \\\n",
    "    .option('kafka.sasl.mechanism', 'SCRAM-SHA-512') \\\n",
    "    .option('kafka.ssl.truststore.location', '/usr/lib/jvm/java-17-openjdk-amd64/lib/security/cacerts') \\\n",
    "    .option('kafka.ssl.truststore.password', 'changeit') \\\n",
    "    .option('maxOffsetsPerTrigger', <Ваш код>) \\\n",
    "    .option('subscribe', <Ваш код>) \\\n",
    "    .option(\"startingOffsets\", <Ваш код>) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea903be6-3956-4e92-af2f-e6475dd65b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_customer = 'yp.workshop.kafka.customer_data'\n",
    "\n",
    "df_customer = spark.readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091') \\\n",
    "    .option('kafka.security.protocol', 'SASL_SSL') \\\n",
    "    .option('kafka.sasl.jaas.config', f'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"{<Ваш код>}\" password=\"{<Ваш код>}\";') \\\n",
    "    .option('kafka.partition.assignment.strategy', 'org.apache.kafka.clients.consumer.RoundRobinAssignor') \\\n",
    "    .option('kafka.sasl.mechanism', 'SCRAM-SHA-512') \\\n",
    "    .option('kafka.ssl.truststore.location', '/usr/lib/jvm/java-17-openjdk-amd64/lib/security/cacerts') \\\n",
    "    .option('kafka.ssl.truststore.password', 'changeit') \\\n",
    "    .option('maxOffsetsPerTrigger', <Ваш код>) \\\n",
    "    .option('subscribe', <Ваш код>) \\\n",
    "    .option(\"startingOffsets\", <Ваш код>) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f64a3-8fd8-4d9b-9400-e20d298869c3",
   "metadata": {},
   "source": [
    "Проверяем загрузку данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fecbe-a178-412e-a27f-6c27576d07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleQuery = df_retail.selectExpr(\"CAST(value AS STRING)\").writeStream.format(\"console\").start()\n",
    "sampleQuery.awaitTermination(5)\n",
    "sampleQuery.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b4e55-f991-4101-b57f-44a85af016ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleQuery = df_customer.selectExpr(\"CAST(value AS STRING)\").writeStream.format(\"console\").start()\n",
    "sampleQuery.awaitTermination(7)\n",
    "sampleQuery.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f843284-085e-4a5a-a560-4bf90eeac88f",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Написать непосредственно преобразование данных. Это преобразование будет выполняться в функции `foreachBatch`:\n",
    "  - Парсинг JSON. Для этого необходима схема сообщения во формате `StructType`;\n",
    "  - Фильтрация, group by, сортировка;\n",
    "  - Запись в базу данных, файл;\n",
    "  - ...\n",
    "  \n",
    "Также необходимо выбрать один из триггеров: https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.streaming.DataStreamWriter.trigger.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c001524-d729-4d15-8a1c-787b936aea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Схема данных retail\n",
    "retail_schema = StructType([ \\\n",
    "    \"\"\" НАПИШИТЕ ВАШ КОД ЗДЕСЬ \"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "103c8adc-acc0-4647-ad95-57e82e9200b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Схема данных customer\n",
    "customer_schema = StructType([ \\\n",
    "   \"\"\" НАПИШИТЕ ВАШ КОД ЗДЕСЬ \"\"\"                              \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de21ebf-46cc-49d3-9825-e20732e30aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не забудьте создать базу данных и коллекции через MongoDB Compass или другой клиент\n",
    "mongo_config = {\n",
    "    \"connection.uri\": \"mongodb://mongodb:27017/\",\n",
    "    \"database\": \"my_database\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf667a-416d-4b91-a8c6-a4b46c6b2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая будет выполняться в forEachBatch\n",
    "def process_retail_data(batch_df, batch_id):\n",
    "    print(batch_df.count())\n",
    "    \"\"\" \n",
    "      Написать логику здесь:\n",
    "          1. Десереализация столбца value\n",
    "          2. Парсинг строк JSON в схему Spark\n",
    "          3. Группируем строки по CustomerID, Country\n",
    "          4. Аггрегация, где собираем все покупки одного клиента в один список\n",
    "    \"\"\"\n",
    "    res = batch_df \\\n",
    "        \"\"\" НАПИШИТЕ ВАШ КОД ЗДЕСЬ \"\"\"\n",
    "    \n",
    "    \n",
    "    # Запись в Mongo с помощью MongoSpark\n",
    "    res.write \\\n",
    "      .format(\"mongodb\") \\\n",
    "      .mode(\"append\") \\\n",
    "      .option(\"collection\", \"retail_data\") \\\n",
    "      .options(**mongo_config) \\\n",
    "      .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4e40810-8327-4f71-9c89-f53435a4fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая будет выполняться в forEachBatch\n",
    "# Для Customer просто пишем строки в коллекцию customer_data\n",
    "def process_customer_data(batch_df, batch_id):\n",
    "    print(batch_df.count())\n",
    "    \"\"\" \n",
    "      Написать логику здесь:\n",
    "          1. Десереализация столбца value\n",
    "          2. Парсинг строк JSON в схему Spark\n",
    "    \"\"\"\n",
    "    res = batch_df \\\n",
    "        \"\"\" НАПИШИТЕ ВАШ КОД ЗДЕСЬ \"\"\"\n",
    "    \n",
    "    # Запись в Mongo с помощью MongoSpark\n",
    "    res.write \\\n",
    "      .format(\"mongodb\") \\\n",
    "      .mode(\"append\") \\\n",
    "      .option(\"collection\", \"customer_data\") \\\n",
    "      .options(**mongo_config) \\\n",
    "      .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225fa9d-7f7d-4637-a4dc-4bcb6eece3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "  Непосредственно обработка потока данных:\n",
    "    1. Определяем папку checkpoints, куда Spark будет записывать свой прогреcc\n",
    "    2. Добавляем функцию в foreachBatch\n",
    "\"\"\"\n",
    "retail_query = df_retail \\\n",
    "  .writeStream \\\n",
    "  .option(\"checkpointLocation\", \"file:///home/jovyan/checkpoints/retail_query\") \\\n",
    "  .foreachBatch(\"\"\" НАПИШИТЕ ВАШ КОД ЗДЕСЬ \"\"\") \\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe07819-3069-4144-97ae-fc043804f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "То же самое для customer\n",
    "\"\"\"\n",
    "customer_query = df_customer \\\n",
    "  .writeStream \\\n",
    "  .option(\"checkpointLocation\", \"file:///home/jovyan/checkpoints/customer_query\") \\\n",
    "  .foreachBatch(\"\"\" НАПИШИТЕ ВАШ КОД ЗДЕСЬ \"\"\") \\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b992d-f7c7-4815-af6c-015feba08933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановить обработку retail:\n",
    "retail_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8b4cb-8a5b-4a93-b427-e4b1b22c7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остановить обработку customer:\n",
    "customer_query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
